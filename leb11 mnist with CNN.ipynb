{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "컨볼루션 네트워크로 MNIST 98% 달성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST자료 불러오기\n",
    "28*28사이즈의 숫자 이미지를 행렬로 표현하였으며 2차원 구조를 정규화 하여 1차원 구조로 표현되있다.\n",
    "라벨의 경우 one-hot방식인데 0~9까지의 숫자를 [0,0,0,0,0,1,0,0,0,0]이런 식으로 표현하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 학습용 데이터 갯수 :  55000\n",
      "총 테스트용 데이터 갯수 :  10000\n",
      "총 검증용 데이터 갯수 :  5000\n",
      "개별 데이터의 행렬 길이 :  784\n",
      "개별 라벨의 행렬 길이 :  10\n"
     ]
    }
   ],
   "source": [
    "print(\"총 학습용 데이터 갯수 : \",len(mnist.train.labels))\n",
    "print(\"총 테스트용 데이터 갯수 : \",len(mnist.test.labels))\n",
    "print(\"총 검증용 데이터 갯수 : \",len(mnist.validation.labels))\n",
    "print(\"개별 데이터의 행렬 길이 : \",len(mnist.train.images[0]))\n",
    "print(\"개별 라벨의 행렬 길이 : \", len(mnist.train.labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가중치 초기화\n",
    "0이 아닌 값으로 가중치를 초기해 줌으로써 원활한 학습을 할수 있게 보조한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xaver_init(n_inputs, n_outputs, uniform = True):\n",
    "    if uniform:\n",
    "        init_range = tf.sqrt(6.0/ (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "\n",
    "    else:\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,784], name=\"images\")\n",
    "label = tf.placeholder(tf.float32,[None,10],name=\"labels\")\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))      # 3x3x1 conv, 32 outputs\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))     # 3x3x32 conv, 64 outputs\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))    # 3x3x32 conv, 128 outputs\n",
    "W4 = tf.Variable(tf.random_normal([2048, 625], stddev=0.01))        # FC 128 * 4 * 4 inputs, 625 outputs\n",
    "W5 = tf.Variable(tf.random_normal([625, 10], stddev=0.01))          # FC 625 inputs, 10 outputs (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습설정 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "# 드롭아웃\n",
    "dropout_cnn_rate = tf.placeholder(tf.float32)\n",
    "dropout_fcc_rate = tf.placeholder(tf.float32)\n",
    "# 전체 학습 횟수\n",
    "training_epochs = 10\n",
    "# 단일 학습에 사용할 자료량\n",
    "batch_size = 200\n",
    "# 학습 결과 노출 간격\n",
    "display_step = 1\n",
    "# 전체 학습 자료를 단일 반복당 학습 자료수로 나누어 한 학습당 반복횟수 산정\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "# 텐서보드용 로그 저장 경로\n",
    "log_path = \"./logs/mnist4cnn_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1_hist = tf.histogram_summary(\"Weights1\",W1)\n",
    "W2_hist = tf.histogram_summary(\"Weights2\",W2)\n",
    "W3_hist = tf.histogram_summary(\"Weights3\",W3)\n",
    "W4_hist = tf.histogram_summary(\"Weights4\",W4)\n",
    "W5_hist = tf.histogram_summary(\"Weights5\",W5)\n",
    "\n",
    "label_hist = tf.histogram_summary(\"labels\",label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_image = tf.reshape(x, [-1, 28, 28, 1], name = 'X-input-reshape')\n",
    "\n",
    "with tf.name_scope(\"L1\") as scope:\n",
    "    L1_H = tf.nn.relu(tf.nn.conv2d(X_image,W1,strides=[1,1,1,1],padding='SAME'))\n",
    "    L1_P = tf.nn.max_pool(L1_H,ksize = [1,2,2,1],strides = [1,2,2,1],padding='SAME')\n",
    "    L1 = tf.nn.dropout(L1_P, dropout_cnn_rate)\n",
    "with tf.name_scope(\"L2\") as scope:\n",
    "    L2_H = tf.nn.relu(tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding='SAME'))\n",
    "    L2_P = tf.nn.max_pool(L2_H,ksize = [1,2,2,1],strides = [1,2,2,1],padding='SAME')\n",
    "    L2 = tf.nn.dropout(L2_P, dropout_cnn_rate)\n",
    "with tf.name_scope(\"L3\") as scope:\n",
    "    L3_H = tf.nn.relu(tf.nn.conv2d(L2,W3,strides=[1,1,1,1],padding='SAME'))\n",
    "    L3_P = tf.nn.max_pool(L3_H,ksize = [1,2,2,1],strides = [1,2,2,1],padding='SAME')\n",
    "    L3_s = tf.reshape(L3_P,[-1,W4.get_shape().as_list()[0]])\n",
    "    L3 = tf.nn.dropout(L3_s, dropout_cnn_rate)\n",
    "with tf.name_scope(\"L4\") as scope:\n",
    "    L4_H = tf.nn.relu(tf.matmul(L3,W4))\n",
    "    L4 = tf.nn.dropout(L4_H, dropout_cnn_rate)\n",
    "with tf.name_scope(\"L-hypothesis\") as scope:\n",
    "    hypothesis  = tf.matmul(L4,W5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비용함수(교차엔트로피)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"cost_func\") as scope:\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(hypothesis,label))\n",
    "    cost_summary = tf.scalar_summary(\"cost\",cost)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"test\") as scope:\n",
    "    real_label = tf.arg_max(label,1) # 실제 라벨\n",
    "    learn_label = tf.arg_max(hypothesis,1) # 머신러닝 결과\n",
    "    correct_prodiction = tf.equal(real_label,learn_label) # 둘다 값이 같으면 true, 틀리면 false\n",
    "\n",
    "    # 정확도\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prodiction,tf.float32))\n",
    "    accuracy_summary = tf.scalar_summary(\"accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 초기화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-0f50547c66e8>:1 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서보드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "터미널에서 프로젝트가 있는 폴더에서 아래 명령어를 실행 시키면 텐서보드가 켜집니다.\n",
      "tensorboard --logdir=./logs/mnist4cnn_1\n"
     ]
    }
   ],
   "source": [
    "merged = tf.merge_all_summaries()\n",
    "try: # 이전 텐서보드 학습로그 삭제\n",
    "    shutil.rmtree(log_path)\n",
    "except:\n",
    "    pass\n",
    "writer = tf.train.SummaryWriter(log_path,sess.graph)\n",
    "print(\"터미널에서 프로젝트가 있는 폴더에서 아래 명령어를 실행 시키면 텐서보드가 켜집니다.\")\n",
    "print(\"tensorboard --logdir={}\".format(log_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    train_count = 0\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost=0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _,c,cs = sess.run([optimizer,cost,cost_summary],feed_dict={x:batch_xs,label:batch_ys,dropout_cnn_rate: 0.7, dropout_fcc_rate: 0.5})\n",
    "            avg_cost = c/total_batch\n",
    "            writer.add_summary(cs,train_count) # 매 batch_size만큼 학습 할때마다 cost를 텐서보드에 그림\n",
    "        print(\"{}번 학습 cost: {}\".format(epoch+1,avg_cost))\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            feed = {x:mnist.test.images, label: mnist.test.labels,dropout_cnn_rate: 1, dropout_fcc_rate: 1}\n",
    "            summary,_ = sess.run([merged,accuracy],feed_dict=feed)\n",
    "            writer.add_summary(summary,epoch)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    sess.close()\n",
    "    exit()\n",
    "print(\"학습완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, label:mnist.test.labels,dropout_cnn_rate: 1, dropout_fcc_rate: 1}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
